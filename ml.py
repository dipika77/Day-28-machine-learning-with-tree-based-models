#Machine learning with treee based models in python

#classsification and regression Trees (CART)
#Decision tree for classification

#instructions
'''Import DecisionTreeClassifier from sklearn.tree.
Instantiate a DecisionTreeClassifier dt of maximum depth equal to 6.
Fit dt to the training set.
Predict the test set labels and assign the result to y_pred.'''

# Import DecisionTreeClassifier from sklearn.tree
from sklearn.tree import DecisionTreeClassifier

# Instantiate a DecisionTreeClassifier 'dt' with a maximum depth of 6
dt = DecisionTreeClassifier(max_depth=6, random_state=SEED)

# Fit dt to the training set
dt.fit(X_train, y_train)

# Predict test set labels
y_pred = dt.predict(X_test)
print(y_pred[0:5])


#instructions
'''Import the function accuracy_score from sklearn.metrics.
Predict the test set labels and assign the obtained array to y_pred.
Evaluate the test set accuracy score of dt by calling accuracy_score() and assign the value to acc.'''

# Import accuracy_score
from sklearn.metrics import accuracy_score

# Predict test set labels
y_pred = dt.predict(X_test)

# Compute test set accuracy  
acc = accuracy_score(y_test, y_pred)
print("Test set accuracy: {:.2f}".format(acc))


#instructions
'''Import LogisticRegression from sklearn.linear_model.
Instantiate a LogisticRegression model and assign it to logreg.
Fit logreg to the training set.
Review the plot generated by plot_labeled_decision_regions()'''

# Import LogisticRegression from sklearn.linear_model
from sklearn.linear_model import LogisticRegression

# Instatiate logreg
logreg = LogisticRegression(random_state=1)

# Fit logreg to the training set
logreg.fit(X_train, y_train)

# Define a list called clfs containing the two classifiers logreg and dt
clfs = [logreg, dt]

# Review the decision regions of the two classifiers
plot_labeled_decision_regions(X_test, y_test, clfs)



#classification Tree Learning
#instructions
'''Import DecisionTreeClassifier from sklearn.tree.
Instantiate a DecisionTreeClassifier dt_entropy with a maximum depth of 8.
Set the information criterion to 'entropy'.
Fit dt_entropy on the training set.'''

# Import DecisionTreeClassifier from sklearn.tree
from sklearn.tree import DecisionTreeClassifier

# Instantiate dt_entropy, set 'entropy' as the information criterion
dt_entropy = DecisionTreeClassifier(max_depth=8, criterion='entropy', random_state=1)

# Fit dt_entropy to the training set
dt_entropy.fit(X_train, y_train)



#instructions
'''Import accuracy_score from sklearn.metrics.
Predict the test set labels of dt_entropy and assign the result to y_pred.
Evaluate the test set accuracy of dt_entropy and assign the result to accuracy_entropy.
Review accuracy_entropy and accuracy_gini.'''

# Import accuracy_score from sklearn.metrics
from sklearn.metrics import accuracy_score

# Use dt_entropy to predict test set labels
y_pred = dt_entropy.predict(X_test)

# Evaluate accuracy_entropy
accuracy_entropy = accuracy_score(y_test, y_pred)

# Print accuracy_entropy
print(f'Accuracy achieved by using entropy: {accuracy_entropy:.3f}')

# Print accuracy_gini
print(f'Accuracy achieved by using the gini index: {accuracy_gini:.3f}')


#Decision Tree for Regression
#instructions
'''Import DecisionTreeRegressor from sklearn.tree.
Instantiate a DecisionTreeRegressor dt with maximum depth 8 and min_samples_leaf set to 0.13.
Fit dt to the training set.'''

# Import DecisionTreeRegressor from sklearn.tree
from sklearn.tree import DecisionTreeRegressor

# Instantiate dt
dt = DecisionTreeRegressor(max_depth= 8,
            min_samples_leaf = 0.13,
            random_state=3)

# Fit dt to the training set
dt.fit(X_train, y_train)


#instructions
'''Import the function mean_squared_error as MSE from sklearn.metrics.
Predict the test set labels and assign the output to y_pred.
Compute the test set MSE by calling MSE and assign the result to mse_dt.
Compute the test set RMSE and assign it to rmse_dt.'''

# Import mean_squared_error from sklearn.metrics as MSE
from sklearn.metrics import mean_squared_error as MSE

# Compute y_pred
y_pred = dt.predict(X_test)

# Compute mse_dt
mse_dt = MSE(y_test, y_pred)

# Compute rmse_dt
rmse_dt = mse_dt ** (1/2)

# Print rmse_dt
print("Test set RMSE of dt: {:.2f}".format(rmse_dt))


#instructions
'''Predict test set labels using the linear regression model (lr) and assign the result to y_pred_lr.
Compute the test set MSE and assign the result to mse_lr.
Compute the test set RMSE and assign the result to rmse_lr'''

# Predict test set labels 
y_pred_lr = lr.predict(X_test)

# Compute mse_lr
mse_lr = MSE(y_test, y_pred_lr)

# Compute rmse_lr
rmse_lr = mse_lr**(1/2)
# Print rmse_lr
print('Linear Regression test set RMSE: {:.2f}'.format(rmse_lr))

# Print rmse_dt
print('Regression Tree test set RMSE: {:.2f}'.format(rmse_dt))



#the bias variance tradeoff
#Diagnose bias and variance problems
#instructions
'''Import train_test_split from sklearn.model_selection.
Split the data into 70% train and 30% test.
Instantiate a DecisionTreeRegressor with max depth 4 and min_samples_leaf set to 0.26.'''

# Import train_test_split from sklearn.model_selection
from sklearn.model_selection import train_test_split

# Set SEED for reproducibility
SEED = 1

# Split the data into 70% train and 30% test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED)

# Instantiate a DecisionTreeRegressor dt
dt = DecisionTreeRegressor(max_depth = 4, min_samples_leaf = 0.26, random_state=SEED)



#instructions
'''Compute dt's 10-fold cross-validated MSE by setting the scoring argument to 'neg_mean_squared_error'.
Compute RMSE from the obtained MSE scores.'''

# Compute the array containing the 10-folds CV MSEs
MSE_CV_scores = - cross_val_score(dt,X_train, y_train, cv= 10, 
                       scoring ='neg_mean_squared_error',
                       n_jobs=-1)

# Compute the 10-folds CV RMSE
RMSE_CV = (MSE_CV_scores.mean())**(1/2)

# Print RMSE_CV
print('CV RMSE: {:.2f}'.format(RMSE_CV))


#instructions
'''Import mean_squared_error as MSE from sklearn.metrics.
Fit dt to the training set.
Predict dt's training set labels and assign the result to y_pred_train.
Evaluate dt's training set RMSE and assign it to RMSE_train'''

# Import mean_squared_error from sklearn.metrics as MSE
from sklearn.metrics import mean_squared_error as MSE

# Fit dt to the training set
dt.fit(X_train, y_train)

# Predict the labels of the training set
y_pred_train = dt.predict(X_train)

# Evaluate the training set RMSE of dt
RMSE_train = (MSE(y_train, y_pred_train))**(1/2)

# Print RMSE_train
print('Train RMSE: {:.2f}'.format(RMSE_train))


#Ensemble Learning
#instructions
'''Instantiate a Logistic Regression classifier and assign it to lr.
Instantiate a KNN classifier that considers 27 nearest neighbors and assign it to knn.
Instantiate a Decision Tree Classifier with the parameter min_samples_leaf set to 0.13 and assign it to dt.'''

# Set seed for reproducibility
SEED=1

# Instantiate lr
lr = LogisticRegression(random_state=SEED)

# Instantiate knn
knn = KNN(n_neighbors= 27)

# Instantiate dt
dt = DecisionTreeClassifier(min_samples_leaf= 0.13, random_state=SEED)

# Define the list classifiers
classifiers = [('Logistic Regression', lr), ('K Nearest Neighbours', knn), ('Classification Tree', dt)]



#instructions
'''Iterate over the tuples in classifiers. Use clf_name and clf as the for loop variables:
Fit clf to the training set.
Predict clf's test set labels and assign the results to y_pred.
Evaluate the test set accuracy of clf and print the result.'''

# Iterate over the pre-defined list of classifiers
for clf_name, clf in classifiers:    
 
    # Fit clf to the training set
    clf.fit(X_train,y_train)   
   
    # Predict y_pred
    y_pred = clf.predict(X_test)
    
    # Calculate accuracy
    accuracy = accuracy_score(y_test, y_pred) 
   
    # Evaluate clf's accuracy on the test set
    print('{:s} : {:.3f}'.format(clf_name, accuracy))
    
    
    
#instructions
'''Import VotingClassifier from sklearn.ensemble.
Instantiate a VotingClassifier by setting the parameter estimators to classifiers and assign it to vc.
Fit vc to the training set.
Evaluate vc's test set accuracy using the test set predictions y_pred.'''

# Import VotingClassifier from sklearn.ensemble
from sklearn.ensemble import VotingClassifier

# Instantiate a VotingClassifier vc
vc = VotingClassifier(estimators= classifiers)     

# Fit vc to the training set
vc.fit(X_train, y_train)   

# Evaluate the test set predictions
y_pred = vc.predict(X_test)

# Calculate accuracy score
accuracy = accuracy_score(y_test, y_pred)
print('Voting Classifier: {:.3f}'.format(accuracy))


